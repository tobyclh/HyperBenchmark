# HyperBenchmark
Benchmarking hyper parameter tuning software.


## Approach (Important!)
There is no way to draw concrete conclusion on which framework will work the best for your particular problem, so this repo is NOT an attempt to do that. Instead this repo provides a quick and dirty way to test all frameworks for your problem. We also provide result on toy problems but they are not to be seen as definitive and should be taken with a large grain of salt.


## Targets
Frameworks that we plan to benchmark
- [Optuna](https://github.com/pfnet/optuna)
- [HyperOpt](https://github.com/hyperopt/hyperopt)
- [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)
- [LightGBM](https://github.com/Microsoft/LightGBM)

## Toy Problems Result
Below are exactly what the title say it is, result of different frameworks on toy problem, which is most likely, different from your problem. If you plan on making decision on which framework to use, instead of refering to result below, try our benchmark suite below.


# HyperBenchmark Suite
## Installation
We assume you have all the frameworks installed.



## Why are you doing this?
I need some hyperparameter tuning packages for multiple projects that I am currently working on. I am not affiliated with any of the works.